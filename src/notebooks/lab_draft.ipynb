{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "nnUNet_raw_data_base is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "RESULTS_FOLDER is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n"
     ]
    }
   ],
   "source": [
    "import sys, string, random\n",
    "from datetime import datetime\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "sys.path.append('../')\n",
    "from data_utils import MNMv2DataModule\n",
    "from unet import LightningSegmentationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load configs\n",
    "mnmv2_config   = OmegaConf.load('../../configs/mnmv2.yaml')\n",
    "unet_config    = OmegaConf.load('../../configs/monai_unet.yaml')\n",
    "trainer_config = OmegaConf.load('../../configs/unet_trainer.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init datamodule\n",
    "datamodule = MNMv2DataModule(\n",
    "    data_dir=mnmv2_config.data_dir,\n",
    "    vendor_assignment=mnmv2_config.vendor_assignment,\n",
    "    batch_size=mnmv2_config.batch_size,\n",
    "    binary_target=mnmv2_config.binary_target,\n",
    "    non_empty_target=mnmv2_config.non_empty_target,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4551\n"
     ]
    }
   ],
   "source": [
    "datamodule.setup(stage='fit')\n",
    "\n",
    "train = datamodule.train_dataloader()\n",
    "print(len(train.generator._data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class MNMv2Subset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input,\n",
    "        target,\n",
    "        # weight\n",
    "    ):\n",
    "        self.input = input\n",
    "        self.target = target\n",
    "        # self.weight = weight\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input\": self.input[idx], \n",
    "            \"target\": self.target[idx],\n",
    "        }\n",
    "\n",
    "datamodule.setup(stage='test')  # Получаем доступ к тестовому набору\n",
    "test_inputs = torch.stack([sample[\"input\"] for sample in datamodule.mnm_test])\n",
    "test_targets = torch.stack([sample[\"target\"] for sample in datamodule.mnm_test])\n",
    "\n",
    "train_dataset_from_test = MNMv2Subset(\n",
    "    input=test_inputs,\n",
    "    target=test_targets\n",
    ")\n",
    "\n",
    "# Заменяем обучающий набор на новый датасет из тестовых данных\n",
    "datamodule.mnm_train = train_dataset_from_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightningSegmentationModel(\n",
      "  (model): UNet(\n",
      "    (model): Sequential(\n",
      "      (0): ResidualUnit(\n",
      "        (conv): Sequential(\n",
      "          (unit0): Convolution(\n",
      "            (conv): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (adn): ADN(\n",
      "              (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (D): Dropout(p=0.0, inplace=False)\n",
      "              (A): PReLU(num_parameters=1)\n",
      "            )\n",
      "          )\n",
      "          (unit1): Convolution(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (adn): ADN(\n",
      "              (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (D): Dropout(p=0.0, inplace=False)\n",
      "              (A): PReLU(num_parameters=1)\n",
      "            )\n",
      "          )\n",
      "          (unit2): Convolution(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (adn): ADN(\n",
      "              (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (D): Dropout(p=0.0, inplace=False)\n",
      "              (A): PReLU(num_parameters=1)\n",
      "            )\n",
      "          )\n",
      "          (unit3): Convolution(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (adn): ADN(\n",
      "              (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "              (D): Dropout(p=0.0, inplace=False)\n",
      "              (A): PReLU(num_parameters=1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (residual): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (1): SkipConnection(\n",
      "        (submodule): Sequential(\n",
      "          (0): ResidualUnit(\n",
      "            (conv): Sequential(\n",
      "              (unit0): Convolution(\n",
      "                (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "                (adn): ADN(\n",
      "                  (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                  (D): Dropout(p=0.0, inplace=False)\n",
      "                  (A): PReLU(num_parameters=1)\n",
      "                )\n",
      "              )\n",
      "              (unit1): Convolution(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (adn): ADN(\n",
      "                  (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                  (D): Dropout(p=0.0, inplace=False)\n",
      "                  (A): PReLU(num_parameters=1)\n",
      "                )\n",
      "              )\n",
      "              (unit2): Convolution(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (adn): ADN(\n",
      "                  (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                  (D): Dropout(p=0.0, inplace=False)\n",
      "                  (A): PReLU(num_parameters=1)\n",
      "                )\n",
      "              )\n",
      "              (unit3): Convolution(\n",
      "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                (adn): ADN(\n",
      "                  (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                  (D): Dropout(p=0.0, inplace=False)\n",
      "                  (A): PReLU(num_parameters=1)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (residual): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "          )\n",
      "          (1): SkipConnection(\n",
      "            (submodule): Sequential(\n",
      "              (0): ResidualUnit(\n",
      "                (conv): Sequential(\n",
      "                  (unit0): Convolution(\n",
      "                    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "                    (adn): ADN(\n",
      "                      (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                      (D): Dropout(p=0.0, inplace=False)\n",
      "                      (A): PReLU(num_parameters=1)\n",
      "                    )\n",
      "                  )\n",
      "                  (unit1): Convolution(\n",
      "                    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                    (adn): ADN(\n",
      "                      (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                      (D): Dropout(p=0.0, inplace=False)\n",
      "                      (A): PReLU(num_parameters=1)\n",
      "                    )\n",
      "                  )\n",
      "                  (unit2): Convolution(\n",
      "                    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                    (adn): ADN(\n",
      "                      (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                      (D): Dropout(p=0.0, inplace=False)\n",
      "                      (A): PReLU(num_parameters=1)\n",
      "                    )\n",
      "                  )\n",
      "                  (unit3): Convolution(\n",
      "                    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                    (adn): ADN(\n",
      "                      (N): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                      (D): Dropout(p=0.0, inplace=False)\n",
      "                      (A): PReLU(num_parameters=1)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (residual): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "              )\n",
      "              (1): SkipConnection(\n",
      "                (submodule): Sequential(\n",
      "                  (0): ResidualUnit(\n",
      "                    (conv): Sequential(\n",
      "                      (unit0): Convolution(\n",
      "                        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                        (adn): ADN(\n",
      "                          (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                          (D): Dropout(p=0.0, inplace=False)\n",
      "                          (A): PReLU(num_parameters=1)\n",
      "                        )\n",
      "                      )\n",
      "                      (unit1): Convolution(\n",
      "                        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                        (adn): ADN(\n",
      "                          (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                          (D): Dropout(p=0.0, inplace=False)\n",
      "                          (A): PReLU(num_parameters=1)\n",
      "                        )\n",
      "                      )\n",
      "                      (unit2): Convolution(\n",
      "                        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                        (adn): ADN(\n",
      "                          (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                          (D): Dropout(p=0.0, inplace=False)\n",
      "                          (A): PReLU(num_parameters=1)\n",
      "                        )\n",
      "                      )\n",
      "                      (unit3): Convolution(\n",
      "                        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                        (adn): ADN(\n",
      "                          (N): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                          (D): Dropout(p=0.0, inplace=False)\n",
      "                          (A): PReLU(num_parameters=1)\n",
      "                        )\n",
      "                      )\n",
      "                    )\n",
      "                    (residual): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  )\n",
      "                  (1): Swivel(\n",
      "                    (swivel): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (swivel): Identity()\n",
      "              )\n",
      "              (2): Sequential(\n",
      "                (0): Convolution(\n",
      "                  (conv): ConvTranspose2d(192, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "                  (adn): ADN(\n",
      "                    (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                    (D): Dropout(p=0.0, inplace=False)\n",
      "                    (A): PReLU(num_parameters=1)\n",
      "                  )\n",
      "                )\n",
      "                (1): ResidualUnit(\n",
      "                  (conv): Sequential(\n",
      "                    (unit0): Convolution(\n",
      "                      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                      (adn): ADN(\n",
      "                        (N): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                        (D): Dropout(p=0.0, inplace=False)\n",
      "                        (A): PReLU(num_parameters=1)\n",
      "                      )\n",
      "                    )\n",
      "                  )\n",
      "                  (residual): Identity()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (swivel): Identity()\n",
      "          )\n",
      "          (2): Sequential(\n",
      "            (0): Convolution(\n",
      "              (conv): ConvTranspose2d(64, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "              (adn): ADN(\n",
      "                (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                (D): Dropout(p=0.0, inplace=False)\n",
      "                (A): PReLU(num_parameters=1)\n",
      "              )\n",
      "            )\n",
      "            (1): ResidualUnit(\n",
      "              (conv): Sequential(\n",
      "                (unit0): Convolution(\n",
      "                  (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (adn): ADN(\n",
      "                    (N): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "                    (D): Dropout(p=0.0, inplace=False)\n",
      "                    (A): PReLU(num_parameters=1)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (residual): Identity()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (swivel): Identity()\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Convolution(\n",
      "          (conv): ConvTranspose2d(32, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "        (1): ResidualUnit(\n",
      "          (conv): Sequential(\n",
      "            (unit0): Convolution(\n",
      "              (conv): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (residual): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss): DiceCELoss(\n",
      "    (dice): DiceLoss()\n",
      "    (cross_entropy): CrossEntropyLoss()\n",
      "    (binary_cross_entropy): BCEWithLogitsLoss()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "\n",
    "cfg = OmegaConf.create({\n",
    "    'unet_config': unet_config,\n",
    "    'binary_target': True if unet_config.out_channels == 1 else False,\n",
    "    'lr': unet_config.lr,\n",
    "    'patience': unet_config.patience,\n",
    "    'dataset': OmegaConf.to_container(mnmv2_config),\n",
    "    'unet': OmegaConf.to_container(unet_config),\n",
    "    'trainer': OmegaConf.to_container(trainer_config)\n",
    "})\n",
    "\n",
    "model = LightningSegmentationModel(cfg=cfg)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiThreadedAugmenter' object has no attribute 'data_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train \u001b[38;5;241m=\u001b[39m datamodule\u001b[38;5;241m.\u001b[39mtrain_dataloader()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_loader\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiThreadedAugmenter' object has no attribute 'data_loader'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.model.0.conv.unit0.conv.weight: requires_grad = False\n",
      "model.model.0.conv.unit0.conv.bias: requires_grad = False\n",
      "model.model.0.conv.unit0.adn.A.weight: requires_grad = False\n",
      "model.model.0.conv.unit1.conv.weight: requires_grad = False\n",
      "model.model.0.conv.unit1.conv.bias: requires_grad = False\n",
      "model.model.0.conv.unit1.adn.A.weight: requires_grad = False\n",
      "model.model.0.conv.unit2.conv.weight: requires_grad = False\n",
      "model.model.0.conv.unit2.conv.bias: requires_grad = False\n",
      "model.model.0.conv.unit2.adn.A.weight: requires_grad = False\n",
      "model.model.0.conv.unit3.conv.weight: requires_grad = False\n",
      "model.model.0.conv.unit3.conv.bias: requires_grad = False\n",
      "model.model.0.conv.unit3.adn.A.weight: requires_grad = False\n",
      "model.model.0.residual.weight: requires_grad = False\n",
      "model.model.0.residual.bias: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit0.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit0.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit0.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit1.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit1.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit1.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit2.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit2.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit2.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit3.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit3.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.0.conv.unit3.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.0.residual.weight: requires_grad = False\n",
      "model.model.1.submodule.0.residual.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit0.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit0.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit0.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit1.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit1.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit1.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit2.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit2.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit2.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit3.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit3.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.conv.unit3.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.residual.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.0.residual.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit0.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit0.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit0.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit1.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit1.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit1.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit2.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit2.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit2.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit3.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit3.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.conv.unit3.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.residual.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.1.submodule.0.residual.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.2.0.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.2.0.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.2.0.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.2.1.conv.unit0.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.2.1.conv.unit0.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.1.submodule.2.1.conv.unit0.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.2.0.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.2.0.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.2.0.adn.A.weight: requires_grad = False\n",
      "model.model.1.submodule.2.1.conv.unit0.conv.weight: requires_grad = False\n",
      "model.model.1.submodule.2.1.conv.unit0.conv.bias: requires_grad = False\n",
      "model.model.1.submodule.2.1.conv.unit0.adn.A.weight: requires_grad = False\n",
      "model.model.2.0.conv.weight: requires_grad = True\n",
      "model.model.2.0.conv.bias: requires_grad = True\n",
      "model.model.2.0.adn.A.weight: requires_grad = True\n",
      "model.model.2.1.conv.unit0.conv.weight: requires_grad = True\n",
      "model.model.2.1.conv.unit0.conv.bias: requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "# print(model.model.model[:2])\n",
    "for param in model.model.model[:2].parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Проверить, что заморожено\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "/home/mikhelson/MedImSeg-Lab24/CLUE/lib/python3.8/site-packages/lightning/pytorch/plugins/precision/amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# infered variable\n",
    "patience = unet_config.patience * 2\n",
    "\n",
    "now = datetime.now()\n",
    "filename = 'mnmv2-' + now.strftime(\"%H-%M_%d-%m-%Y\")\n",
    "\n",
    "# init trainer\n",
    "if trainer_config.logging:\n",
    "    wandb.finish()\n",
    "    logger = WandbLogger(\n",
    "        project=\"lightning\", \n",
    "        log_model=True, \n",
    "        name=filename\n",
    "    )\n",
    "else:\n",
    "    logger = None\n",
    "\n",
    "# trainer\n",
    "trainer = L.Trainer(\n",
    "    limit_train_batches=trainer_config.limit_train_batches,\n",
    "    max_epochs=trainer_config.max_epochs,\n",
    "    logger=logger,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor=trainer_config.early_stopping.monitor, \n",
    "            mode=trainer_config.early_stopping.mode, \n",
    "            patience=patience\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            dirpath=trainer_config.model_checkpoint.dirpath,\n",
    "            filename=filename,\n",
    "            save_top_k=trainer_config.model_checkpoint.save_top_k, \n",
    "            monitor=trainer_config.model_checkpoint.monitor,\n",
    "        )\n",
    "    ],\n",
    "    precision='16-mixed',\n",
    "    gradient_clip_val=0.5,\n",
    "    devices=[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1069035f\u001b[0m (\u001b[33mrivman\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241218_130928-l2ulrmiy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rivman/lightning/runs/l2ulrmiy' target=\"_blank\">mnmv2-13-09_18-12-2024</a></strong> to <a href='https://wandb.ai/rivman/lightning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rivman/lightning' target=\"_blank\">https://wandb.ai/rivman/lightning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rivman/lightning/runs/l2ulrmiy' target=\"_blank\">https://wandb.ai/rivman/lightning/runs/l2ulrmiy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name  | Type       | Params | Mode \n",
      "---------------------------------------------\n",
      "0 | model | UNet       | 794 K  | train\n",
      "1 | loss  | DiceCELoss | 0      | train\n",
      "---------------------------------------------\n",
      "794 K     Trainable params\n",
      "0         Non-trainable params\n",
      "794 K     Total params\n",
      "3.178     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 50/50 [00:12<00:00,  4.07it/s, v_num=rmiy]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 50/50 [00:12<00:00,  4.05it/s, v_num=rmiy]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:03<00:00, 11.75it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_dsc            0.7333963513374329\n",
      "        test_loss           0.5420395135879517\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "datamodule.setup(stage='test')\n",
    "# model = model.to(device)\n",
    "model.eval()\n",
    "test_perf = trainer.test(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10508/3995855781.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': {'data_dir': '../../../../../data/MNM/', 'vendor_assignment': {'train': 'siemens', 'test': 'ge'}, 'batch_size': 32, 'binary_target': False, 'non_empty_target': False}, 'unet': {'n_filters_init': 16, 'depth': 4, 'spatial_dims': 2, 'in_channels': 1, 'out_channels': 4, 'num_res_units': 4, 'lr': 0.001, 'patience': 5}, 'trainer': {'train_transforms': 'global_transforms', 'limit_train_batches': 50, 'max_epochs': 100, 'early_stopping': {'monitor': 'val_loss', 'mode': 'min'}, 'model_checkpoint': {'save_top_k': 2, 'dirpath': '../../pre-trained/monai-unets', 'monitor': 'val_loss'}, 'logging': True}}\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '../../checkpoints/mnmv2-11-52_29-10-2024.ckpt'\n",
    "\n",
    "load_as_lightning_module = False\n",
    "load_as_pytorch_module = True\n",
    "\n",
    "if load_as_lightning_module:\n",
    "    unet_config    = OmegaConf.load('../../configs/monai_unet.yaml')\n",
    "    unet = UNet(\n",
    "        spatial_dims=unet_config.spatial_dims,\n",
    "        in_channels=unet_config.in_channels,\n",
    "        out_channels=unet_config.out_channels,\n",
    "        channels=[unet_config.n_filters_init * 2 ** i for i in range(unet_config.depth)],\n",
    "        strides=[2] * (unet_config.depth - 1),\n",
    "        num_res_units=4\n",
    "    )\n",
    "    model = LightningSegmentationModel.load_from_checkpoint(\n",
    "        checkpoint_path,\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "        model=unet,\n",
    "        binary_target=True if unet_config.out_channels == 1 else False,\n",
    "        lr=unet_config.lr,\n",
    "        patience=unet_config.patience,\n",
    "        # cfg=OmegaConf.to_container(unet_config)\n",
    "    )\n",
    "\n",
    "elif load_as_pytorch_module:\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "    model_state_dict = checkpoint['state_dict']\n",
    "    model_state_dict = {k.replace('model.model.', 'model.'): v for k, v in model_state_dict.items() if k.startswith('model.')}\n",
    "    model_config = checkpoint['hyper_parameters']['cfgs']\n",
    "\n",
    "    print(model_config)\n",
    "\n",
    "    unet = UNet(\n",
    "        spatial_dims=model_config['unet']['spatial_dims'],\n",
    "        in_channels=model_config['unet']['in_channels'],\n",
    "        out_channels=model_config['unet']['out_channels'],\n",
    "        channels=[model_config['unet']['n_filters_init'] * 2 ** i for i in range(model_config['unet']['depth'])],\n",
    "        strides=[2] * (model_config['unet']['depth'] - 1),\n",
    "        num_res_units=4\n",
    "    )\n",
    "\n",
    "    unet.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unet_config': {'n_filters_init': 16, 'depth': 4, 'spatial_dims': 2, 'in_channels': 1, 'out_channels': 4, 'num_res_units': 4, 'lr': 0.001, 'patience': 5, 'clue_softmax_t': 1, 'batch_size': 32, 'binary_target': False}, 'binary_target': False, 'lr': 0.001, 'patience': 5, 'dataset': {'data_dir': '/home/mikhelson/MedImSeg-Lab24/data/MNM/', 'vendor_assignment': {'train': 'siemens', 'test': 'ge'}, 'batch_size': 32, 'binary_target': False, 'non_empty_target': False}, 'unet': {'n_filters_init': 16, 'depth': 4, 'spatial_dims': 2, 'in_channels': 1, 'out_channels': 4, 'num_res_units': 4, 'lr': 0.001, 'patience': 5, 'clue_softmax_t': 1, 'batch_size': 32, 'binary_target': False}, 'trainer': {'train_transforms': 'global_transforms', 'limit_train_batches': 50, 'max_epochs': 100, 'early_stopping': {'monitor': 'val_loss', 'mode': 'min'}, 'model_checkpoint': {'save_top_k': 2, 'dirpath': '../../MedImSeg-Lab24/pre-trained/trained_UNets', 'monitor': 'val_loss'}, 'logging': True}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLUE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
